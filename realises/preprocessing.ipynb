{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re # Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ Ð´Ð»Ñ ÐºÐ¾Ð´Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð‘Ð°Ð»ÐºÐ¾Ð½Ð¾Ð², Ñ‚Ð°Ð¼ Ñ‡Ð¸ÑÐ»Ð° ÑÐ¾ ÑÑ‚Ñ€Ð¾ÐºÐ°Ð¼Ð¸ Ð¸ Ð·Ð½Ð°ÐºÐ°Ð¼Ð¸ Ð²Ð¿ÐµÑ€ÐµÐ¼ÐµÑˆÐºÑƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading CSV file\n",
    "df = pd.read_csv('~/Desktop/ds_bootcamp/week3/project/data/_data.csv')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleting Unnecessary columns from data frame\n",
    "df = df.drop(['Unnamed: 0', 'Ð¢Ð¸Ð¿'], axis=1)\n",
    "df = df.drop(['ÐŸÐ°Ñ€ÐºÐ¾Ð²ÐºÐ°'], axis=1) # Ð£Ð±ÐµÑ€Ð°ÐµÐ¼ Ð¿Ð°Ñ€ÐºÐ¾Ð²ÐºÑƒ\n",
    "df = df.drop(['Ð¢ÐµÐ»ÐµÑ„Ð¾Ð½Ñ‹'], axis=1) # Ð£Ð±ÐµÑ€Ð°ÐµÐ¼ Ñ‚ÐµÐ»ÐµÑ„Ð¾Ð½Ñ‹\n",
    "df = df.drop(['ÐŸÐ»Ð¾Ñ‰Ð°Ð´ÑŒ ÐºÐ¾Ð¼Ð½Ð°Ñ‚, Ð¼2'], axis=1) # Ð£Ð±ÐµÑ€Ð°ÐµÐ¼ Ð¿Ð»Ð¾Ñ‰Ð°Ð´Ð¸ ÐºÐ¾Ð¼Ð½Ð°Ñ‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming columns from Russian to English\n",
    "df = df.rename(columns={'ID  Ð¾Ð±ÑŠÑÐ²Ð»ÐµÐ½Ð¸Ñ': 'post_id', 'ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÐºÐ¾Ð¼Ð½Ð°Ñ‚': 'number_of_rooms', \n",
    "                            'ÐœÐµÑ‚Ñ€Ð¾': 'metro', 'ÐÐ´Ñ€ÐµÑ': 'address', 'ÐŸÐ»Ð¾Ñ‰Ð°Ð´ÑŒ, Ð¼2': 'area_m2', 'Ð”Ð¾Ð¼': 'apt_short_desc'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing nan values by the most frequent element \n",
    "df['number_of_rooms'] = df['number_of_rooms'].replace(to_replace=[None], value=df.loc[:, 'number_of_rooms'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating 3 new features in data frame\n",
    "df.insert(2, 'isolated_apt', 0)\n",
    "df.insert(3, 'adjacent_apt', 0)\n",
    "df.insert(4, 'iso_adj_apt', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling in 3 new columns by 1 if Apt has specific features related to columns \n",
    "splited_list_of_num_rooms = [i.split(', ') for i in df['number_of_rooms']]\n",
    "\n",
    "for i in range(len(splited_list_of_num_rooms)):\n",
    "    if splited_list_of_num_rooms[i][0].isdigit():\n",
    "        df.loc[i, 'number_of_rooms'] = splited_list_of_num_rooms[i][0]\n",
    "        \n",
    "        if len(splited_list_of_num_rooms[i]) > 1:\n",
    "            if splited_list_of_num_rooms[i][1] == 'Ð˜Ð·Ð¾Ð»Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð°Ñ':\n",
    "                df.loc[i, 'isolated_apt'] = 1\n",
    "            \n",
    "            if splited_list_of_num_rooms[i][1] == 'Ð¡Ð¼ÐµÐ¶Ð½Ð°Ñ':\n",
    "                df.loc[i, 'adjacent_apt'] = 1\n",
    "            \n",
    "            if splited_list_of_num_rooms[i][1] == 'ÐžÐ±Ð° Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ð°':\n",
    "                df.loc[i, 'iso_adj_apt'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing nan values by the most frequent element \n",
    "df['metro'] = df['metro'].replace(to_replace=[None], value=df.loc[:, 'metro'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding new columns related to Metro feature\n",
    "df.insert(6, 'time_to_get_metro', 0)\n",
    "df.insert(7, 'by_car', 0)\n",
    "df.insert(8, 'by_walk', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ð¿ÐµÑˆÐºÐ¾Ð¼', 'Ð¼Ð°ÑˆÐ¸Ð½Ðµ'], dtype=object)"
      ]
     },
     "execution_count": 1192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check uniqueness of transport type and create lists for future distribution\n",
    "splited_list_of_metro = [metro.split(' (') for metro in df['metro']]\n",
    "lst_type_of_transport_metro = []\n",
    "lst_time_to_get_metro = []\n",
    "lst_name_of_metro = []\n",
    "for i in splited_list_of_metro:\n",
    "    lst_type_of_transport_metro.append(i[1].split()[-1].rstrip(')'))\n",
    "    lst_time_to_get_metro.append(i[1].split()[0])\n",
    "    lst_name_of_metro.append(i[0])\n",
    "    \n",
    "unique_lst = pd.Series(lst_type_of_transport_metro).unique()\n",
    "unique_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling in 2 new columns by 1 if Metro has specific features related to columns\n",
    "#And adding amount of min to get metro in 1 column\n",
    "for i in range(len(splited_list_of_metro)):\n",
    "    df.loc[i, 'metro'] = lst_name_of_metro[i]\n",
    "    df.loc[i, 'time_to_get_metro'] = lst_time_to_get_metro[i]\n",
    "    \n",
    "    if lst_type_of_transport_metro[i] == 'Ð¿ÐµÑˆÐºÐ¾Ð¼':\n",
    "        df.loc[i, 'by_walk'] = 1\n",
    "    else:\n",
    "        df.loc[i, 'by_car'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bul's part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1195,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1=df['Ð¦ÐµÐ½Ð°']\n",
    "rent_price_curr = temp1.apply(lambda x:x.split('/')[0].split())\n",
    "rent_price = rent_price_curr.apply(lambda x:x[0])\n",
    "# Ð¦ÐµÐ½Ð° Ð°Ñ€ÐµÐ½Ð´Ñ‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1196,
   "metadata": {},
   "outputs": [],
   "source": [
    "currency = rent_price_curr.apply(lambda x:x[1]) # Ð’Ð°Ð»ÑŽÑ‚Ð° Ð°Ñ€ÐµÐ½Ð´Ñ‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1197,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3=temp1.apply(lambda x:x.split('Ð¡Ñ€Ð¾Ðº Ð°Ñ€ÐµÐ½Ð´Ñ‹ - '))\n",
    "stay_time=s3.apply(lambda x:x[1].split(',')[0]) # Ð’Ð¸Ð´Ñ‹ ÑÑ€Ð¾ÐºÐ¾Ð²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1198,
   "metadata": {},
   "outputs": [],
   "source": [
    "deposite = temp1.apply(lambda x:x.split('Ð—Ð°Ð»Ð¾Ð³ - '))\n",
    "test1 = deposite.apply(lambda x:len(x))\n",
    "bool_series1 = test1==2\n",
    "\n",
    "deposite[bool_series1] = deposite[bool_series1].apply(lambda x:x[1].split(',')[0].split(' '))\n",
    "deposite[~bool_series1] = '00'\n",
    "\n",
    "deposite_value = deposite.apply(lambda x:x[0]) # Ð’ÑÐµ Ð·Ð°Ð»Ð¾Ð³Ð¸, ÐµÑÐ»Ð¸ Ð½ÐµÑ‚Ñƒ = Ñ‚Ð¾ 0 ÑÑ‚Ñ€Ð¾ÐºÐ¾Ð¹\n",
    "deposite_currency = deposite.apply(lambda x:x[1]) # Ð’ÑÐµ Ð²Ð°Ð»ÑŽÑ‚Ñ‹, ÐµÑÐ»Ð¸ Ð½ÐµÑ‚Ñƒ = Ñ‚Ð¾ 0 ÑÑ‚Ñ€Ð¾ÐºÐ¾Ð¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1199,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_pay = temp1.apply(lambda x:x.split('ÐŸÑ€ÐµÐ´Ð¾Ð¿Ð»Ð°Ñ‚Ð° ')[-1])\n",
    "\n",
    "pre_pay_months = pre_pay.apply(lambda x:x.split(' ')[0]) \n",
    "\n",
    "pre_pay_bool = pre_pay.apply(lambda x:x.split(' ')[-1])\n",
    "pre_pay_bool[(pre_pay_bool=='Ð”Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹')|(pre_pay_bool=='Ð¼ÐµÑÑÑ†ÐµÐ²')]='Ð½ÐµÑ‚Ñƒ'\n",
    "# ÐŸÑ€ÐµÐ´Ð¾Ð¿Ð»Ð°Ñ‚Ð° Ð»Ð¸Ð±Ð¾ \"Ð¼ÐµÑ\", Ð»Ð¸Ð±Ð¾ Ð½ÐµÑ‚Ñƒ - Ð·Ð°Ð¼ÐµÐ½Ð¸Ð» Ð½Ð° \"Ð½ÐµÑ‚Ñƒ\".\n",
    "\n",
    "pre_pay_months = pre_pay_months.astype(float)\n",
    "pre_pay_months[pre_pay_months>12]=0\n",
    "# ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¼ÐµÑÑÑ†ÐµÐ²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1200,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Ð¦ÐµÐ½Ð°'], axis=1) # Ð£Ð±ÐµÑ€Ð°ÐµÐ¼ Ñ†ÐµÐ½Ñƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1201,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(12,'rent_price',rent_price)\n",
    "df.insert(13,'rent_currency',currency)\n",
    "df.insert(14,'stay_time',stay_time)\n",
    "df.insert(15,'deposite',deposite_value)\n",
    "df.insert(16,'deposite_currency',deposite_currency)\n",
    "df.insert(17,'is_prepay',pre_pay_bool)\n",
    "df.insert(18,'prepay_months',pre_pay_months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1202,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ'], axis=1) # Ð£Ð±ÐµÑ€Ð°ÐµÐ¼ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1203,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rent_price']=df['rent_price'].astype(float)\n",
    "df['deposite']=df['deposite'].astype(float)\n",
    "# ÐŸÐµÑ€ÐµÐ²Ð¾Ð´Ð¸Ñ‚ Ñ‡Ð¸ÑÐ»Ð¾Ð²Ñ‹Ðµ Ð²Ð¾ float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1204,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['is_prepay'], axis=1) # Ð£Ð±ÐµÑ€Ð°ÐµÐ¼ Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿Ñ€Ð¸Ð·Ð½Ð°Ðº\n",
    "df['prepay_months'] = df['prepay_months'].astype(int) # Ð¢ÐµÐ¿ÐµÑ€ÑŒ ÐµÑÐ»Ð¸ 0 - Ñ‚Ð¾ Ð½ÐµÑ‚Ñƒ ÐŸÑ€ÐµÐ´Ð¾Ð¿Ð»Ð°Ñ‚Ñ‹, Ð¸Ð»Ð¸ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¼ÐµÑÑÑ†ÐµÐ² Ð¿Ñ€ÐµÐ´Ð¾Ð¿Ð»Ð°Ñ‚Ñ‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1205,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'Ð ÐµÐ¼Ð¾Ð½Ñ‚': 'renovation'}) # ÐŸÐµÑ€ÐµÐ¸Ð¼ÐµÐ½Ð¾Ð²Ñ‹Ð²Ð°ÐµÐ¼ ÐºÐ¾Ð»Ð¾Ð½ÐºÑƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1206,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['renovation']=df['renovation'].fillna('ÐÐµÑ‚Ñƒ') # ÐŸÑ€Ð¾Ð¿ÑƒÑÐºÐ¸ = \"ÐÐµÑ‚Ñƒ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1207,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'Ð‘Ð°Ð»ÐºÐ¾Ð½': 'balcony'}) # ÐŸÐµÑ€ÐµÐ¸Ð¼ÐµÐ½Ð¾Ð²Ñ‹Ð²Ð°ÐµÐ¼ ÐºÐ¾Ð»Ð¾Ð½ÐºÑƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1208,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['balcony']=df['balcony'].fillna('Ð‘Ð°Ð»ÐºÐ¾Ð½ (0), Ð›Ð¾Ð´Ð¶Ð¸Ñ (0)') # ÐŸÑ€Ð¾Ð¿ÑƒÑÐºÐ¸ = 'Ð‘Ð°Ð»ÐºÐ¾Ð½ (0), Ð›Ð¾Ð´Ð¶Ð¸Ñ (0)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1209,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ð—Ð´ÐµÑÑŒ Ð½Ð°Ñ‡Ð¸Ð½Ð°ÐµÑ‚ÑÑ Ð²Ñ‚Ð¾Ñ€Ð°Ñ Ñ‡Ð°ÑÑ‚ÑŒ Ð’Ñ‚Ð¾Ñ€Ð¾Ð³Ð¾ Ñ€ÐµÐ»Ð¸Ð·Ð° = ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ñ†ÐµÐ½Ñ‹ Ð² Ð”Ð¾Ð»Ð»Ð°Ñ€Ñ‹, ÐºÐ¾Ð´Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ ÑÑ‚Ñ€Ð¾ÐºÐ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1210,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.loc[df['renovation'] == 'ÐÐµÑ‚Ñƒ', 'renovation'] = 'Ð‘ÐµÐ· Ñ€ÐµÐ¼Ð¾Ð½Ñ‚Ð°' # ÐŸÐ¾Ð²Ñ‚Ð¾Ñ€ÑÑŽÑ‰Ð¸ÐµÑÑ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ \"ÐÐµÑ‚Ñƒ\" Ð¸ \"Ð‘ÐµÐ· Ñ€ÐµÐ¼Ð¾Ð½Ñ‚Ð°\" = Ñ‚ÐµÐ¿ÐµÑ€ÑŒ Ð²ÐµÐ·Ð´Ðµ \"Ð‘ÐµÐ· Ñ€ÐµÐ¼Ð¾Ð½Ñ‚Ð°\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1211,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "renovation_mapping = {\n",
    "    'Ð•Ð²Ñ€Ð¾Ñ€ÐµÐ¼Ð¾Ð½Ñ‚': 3,\n",
    "    'Ð”Ð¸Ð·Ð°Ð¹Ð½ÐµÑ€ÑÐºÐ¸Ð¹': 4,\n",
    "    'ÐšÐ¾ÑÐ¼ÐµÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹': 2,\n",
    "    'Ð‘ÐµÐ· Ñ€ÐµÐ¼Ð¾Ð½Ñ‚Ð°':1,\n",
    "}\n",
    "\n",
    "df['renovation']=df['renovation'].map(renovation_mapping) # Ð¡Ð´ÐµÐ»Ð°Ð»Ð¸ ÐºÐ¾Ð´Ð¸Ñ€Ð¾Ð²ÐºÑƒ, Ð³Ð´Ðµ 1 = ÑÐ°Ð¼Ñ‹Ð¹ ÑƒÐ¶Ð°ÑÐ½Ñ‹Ð¹ Ñ€ÐµÐ¼Ð¾Ð½Ñ‚, 4 = ÑÐ°Ð¼Ñ‹Ð¹ Ð»ÑƒÑ‡ÑˆÐ¸Ð¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1212,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "convert_to_usd = {'Ñ€ÑƒÐ±.':0.011, '$':1, 'â‚¬':1.07} # Ð¡Ð»Ð¾Ð²Ð°Ñ€ÑŒ Ð¼Ð½Ð¾Ð¶Ð¸Ñ‚ÐµÐ»ÐµÐ¹ Ð¾Ñ‚ Ñ‚ÐµÐºÑƒÑ‰ÐµÐ¹ Ð²Ð°Ð»ÑŽÑ‚Ñ‹ Ð² Ð”Ð¾Ð»Ð»Ð°Ñ€Ñ‹\n",
    "df['rent_price']=df.apply(lambda row: row['rent_price'] * convert_to_usd[row['rent_currency']], axis=1) # ÐŸÐµÑ€ÐµÐ²Ð¾Ð´Ð¸Ð¼ Ð²ÑÐµ Ñ†ÐµÐ½Ñ‹ Ð² Ð”Ð¾Ð»Ð»Ð°Ñ€Ñ‹\n",
    "df = df.drop(['rent_currency'], axis=1) # Ð£Ð±ÐµÑ€Ð°ÐµÐ¼ ÐºÐ¾Ð»Ð¾Ð½ÐºÑƒ Ð²Ð°Ð»ÑŽÑ‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1213,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "convert_to_usd_depo = {'Ñ€ÑƒÐ±.':0.011, '$':1, 'â‚¬':1.07, '0':0.0} # Ð¡Ð»Ð¾Ð²Ð°Ñ€ÑŒ ÑƒÐ¶Ðµ Ð´Ð»Ñ Ð´ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ð², Ñ‚Ð°Ð¼ Ð¸Ñ… ÐºÐ¾Ðµ-Ð³Ð´Ðµ Ð½ÐµÑ‚Ñƒ Ð²Ð°Ð»ÑŽÑ‚Ñ‹ = 0\n",
    "df['deposite'] = df.apply(lambda row: row['deposite'] * convert_to_usd_depo[row['deposite_currency']], axis=1) # ÐŸÐµÑ€ÐµÐ²Ð¾Ð´Ð¸Ð¼ Ð²ÑÐµ Ð´ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ñ‹ Ð² Ð”Ð¾Ð»Ð»Ð°Ñ€Ñ‹\n",
    "df = df.drop(['deposite_currency'], axis=1) # Ð£Ð±ÐµÑ€Ð°ÐµÐ¼ ÐºÐ¾Ð»Ð¾Ð½ÐºÑƒ Ð²Ð°Ð»ÑŽÑ‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1214,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['deposite']=df.apply(lambda row: row['deposite']/row['rent_price'], axis=1) # ÐŸÐµÑ€ÐµÐ²Ð¾Ð´Ð¸Ð¼ Ð¸Ñ… Ð² Ð¿Ñ€Ð¾Ñ†ÐµÐ½Ñ‚Ð½Ð¾Ðµ ÑÐ¾Ð¾Ñ‚Ð½Ð¾ÑˆÐµÐ½Ð¸Ðµ Ð¾Ñ‚ Ñ†ÐµÐ½Ñ‹ Ð·Ð° Ð°Ñ€ÐµÐ½Ð´Ñƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1215,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stay_time_mapping = {\n",
    "    'Ð”Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹': 2,\n",
    "    'ÐÐ° Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð¼ÐµÑÑÑ†ÐµÐ²': 1\n",
    "}\n",
    "\n",
    "df['stay_time']=df['stay_time'].map(stay_time_mapping) # Ð¡Ð´ÐµÐ»Ð°Ð»Ð¸ ÐºÐ¾Ð´Ð¸Ñ€Ð¾Ð²ÐºÑƒ, Ð³Ð´Ðµ 1 = Ð½Ð° Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð¼ÐµÑÑÑ†ÐµÐ², 2 = Ð´Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ ÑÑ€Ð¾Ðº"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1216,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_and_sum_numbers(s):\n",
    "    numbers = re.findall(r'\\d+', s)\n",
    "    return sum(map(int, numbers))\n",
    "\n",
    "df['balcony']=df['balcony'].apply(extract_and_sum_numbers)\n",
    "# Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑ regular expression Ñ Ð½Ð°Ñ…Ð¾Ð¶Ñƒ Ð²ÑÐµ Ñ‡Ð¸ÑÐ»Ð° Ð¸ ÑÑƒÐ¼Ð¼Ð¸Ñ€ÑƒÑŽ Ð¸Ñ…\n",
    "# Ð’ Ð¸Ñ‚Ð¾Ð³Ðµ Ð›Ð¾Ð´Ð¶Ð¸Ñ Ð¸ Ð‘Ð°Ð»ÐºÐ¾Ð½ Ð¿Ð¾ Ð²ÐµÑÑƒ = Ñƒ Ð¼ÐµÐ½Ñ Ñ€Ð°Ð²Ð½Ñ‹, Ð° Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ = ÑÑ‚Ð¾ Ð¸Ñ… ÐºÐ¾Ð»-Ð²Ð¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1217,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.rename(columns={'balcony': 'balcony_count'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1218,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rent_price       float64\n",
       "stay_time          int64\n",
       "deposite         float64\n",
       "prepay_months      int64\n",
       "renovation         int64\n",
       "balcony_count      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 1218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,12:18].dtypes # Ð’ÑÐµ Ð¼Ð¾Ð¸ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nastya's part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1.0\n",
      "1        0.0\n",
      "2        0.0\n",
      "3        1.0\n",
      "4        0.0\n",
      "        ... \n",
      "23363    0.0\n",
      "23364    0.0\n",
      "23365    0.0\n",
      "23366    0.0\n",
      "23367    1.0\n",
      "Name: pets_okay, Length: 23368, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df['pets_okay'] = df['ÐœÐ¾Ð¶Ð½Ð¾ Ñ Ð´ÐµÑ‚ÑŒÐ¼Ð¸/Ð¶Ð¸Ð²Ð¾Ñ‚Ð½Ñ‹Ð¼Ð¸'].apply(lambda x: 1 if isinstance(x, str) and 'ÐœÐ¾Ð¶Ð½Ð¾ Ñ Ð¶Ð¸Ð²Ð¾Ñ‚Ð½Ñ‹Ð¼Ð¸' in x else (0 if isinstance(x, str) else np.nan))\n",
    "mode_pets_okay = df['pets_okay'].mode()[0]\n",
    "df['pets_okay'].fillna(mode_pets_okay, inplace=True)\n",
    "print(df['pets_okay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of each value in 'pets_okay':\n",
      "pets_okay\n",
      "0.0    69.453954\n",
      "1.0    30.546046\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "percent_counts = df['pets_okay'].value_counts(normalize=True) * 100\n",
    "# Print the percentage counts\n",
    "print(\"Percentage of each value in 'pets_okay':\")\n",
    "print(percent_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1.0\n",
      "1        1.0\n",
      "2        1.0\n",
      "3        0.0\n",
      "4        1.0\n",
      "        ... \n",
      "23363    1.0\n",
      "23364    1.0\n",
      "23365    1.0\n",
      "23366    1.0\n",
      "23367    1.0\n",
      "Name: kids_okay, Length: 23368, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df['kids_okay'] = df['ÐœÐ¾Ð¶Ð½Ð¾ Ñ Ð´ÐµÑ‚ÑŒÐ¼Ð¸/Ð¶Ð¸Ð²Ð¾Ñ‚Ð½Ñ‹Ð¼Ð¸'].apply(lambda x: 1 if isinstance(x, str) and 'ÐœÐ¾Ð¶Ð½Ð¾ Ñ Ð´ÐµÑ‚ÑŒÐ¼Ð¸' in x else (0 if isinstance(x, str) else np.nan))\n",
    "mode_kids_okay = df['kids_okay'].mode()[0] # ðŸš§\n",
    "df['kids_okay'].fillna(mode_kids_okay, inplace=True)\n",
    "print(df['kids_okay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of each value in 'kids_okay':\n",
      "kids_okay\n",
      "1.0    98.977234\n",
      "0.0     1.022766\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "percent_counts = df['kids_okay'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Print the percentage counts\n",
    "print(\"Percentage of each value in 'kids_okay':\")\n",
    "print(percent_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_column(df, new_col_name, phrase):\n",
    "    df[new_col_name] = df['Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾'].apply(\n",
    "        lambda x: 1 if isinstance(x, str) and phrase in x else (0 if isinstance(x, str) else np.nan)\n",
    "    )\n",
    "    # Fill NaN values with the mode\n",
    "    mode_value = df[new_col_name].mode()[0]\n",
    "    df[new_col_name].fillna(mode_value, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Create new columns\n",
    "df = create_column(df, 'furniture_in_the_room', 'ÐœÐµÐ±ÐµÐ»ÑŒ Ð² ÐºÐ¾Ð¼Ð½Ð°Ñ‚Ð°Ñ…')\n",
    "df = create_column(df, 'air_conditioner', 'ÐšÐ¾Ð½Ð´Ð¸Ñ†Ð¸Ð¾Ð½ÐµÑ€')\n",
    "df = create_column(df, 'dishwashing', 'ÐŸÐ¾ÑÑƒÐ´Ð¾Ð¼Ð¾ÐµÑ‡Ð½Ð°Ñ Ð¼Ð°ÑˆÐ¸Ð½Ð°')\n",
    "df = create_column(df, 'fridge', 'Ð¥Ð¾Ð»Ð¾Ð´Ð¸Ð»ÑŒÐ½Ð¸Ðº')\n",
    "df = create_column(df, 'internet', 'Ð˜Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of each value in 'furniture_in_the_room':\n",
      "furniture_in_the_room\n",
      "1.0    92.643786\n",
      "0.0     7.356214\n",
      "Name: proportion, dtype: float64\n",
      "Percentage of each value in 'air_conditioner':\n",
      "air_conditioner\n",
      "0.0    62.358781\n",
      "1.0    37.641219\n",
      "Name: proportion, dtype: float64\n",
      "Percentage of each value in 'dishwashing':\n",
      "dishwashing\n",
      "0.0    66.48836\n",
      "1.0    33.51164\n",
      "Name: proportion, dtype: float64\n",
      "Percentage of each value in 'fridge':\n",
      "fridge\n",
      "1.0    88.124786\n",
      "0.0    11.875214\n",
      "Name: proportion, dtype: float64\n",
      "Percentage of each value in 'internet':\n",
      "internet\n",
      "1.0    80.498973\n",
      "0.0    19.501027\n",
      "Name: proportion, dtype: float64\n",
      "       furniture_in_the_room  air_conditioner  dishwashing  fridge  internet\n",
      "0                        1.0              1.0          1.0     1.0       1.0\n",
      "1                        1.0              1.0          1.0     1.0       1.0\n",
      "2                        1.0              1.0          1.0     1.0       1.0\n",
      "3                        1.0              1.0          1.0     1.0       1.0\n",
      "4                        1.0              0.0          1.0     1.0       1.0\n",
      "...                      ...              ...          ...     ...       ...\n",
      "23363                    1.0              1.0          0.0     1.0       1.0\n",
      "23364                    1.0              0.0          0.0     1.0       0.0\n",
      "23365                    0.0              1.0          0.0     1.0       1.0\n",
      "23366                    1.0              1.0          1.0     1.0       0.0\n",
      "23367                    1.0              1.0          1.0     1.0       1.0\n",
      "\n",
      "[23368 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Checking descriptive stats for each main feature\n",
    "def calculate_percentage(df, column_name):\n",
    "    percent_counts = df[column_name].value_counts(normalize=True) * 100\n",
    "    print(f\"Percentage of each value in '{column_name}':\")\n",
    "    print(percent_counts)\n",
    "\n",
    "calculate_percentage(df, 'furniture_in_the_room')\n",
    "calculate_percentage(df, 'air_conditioner')\n",
    "calculate_percentage(df, 'dishwashing')\n",
    "# Doing reality check - these columns should largely have 1 \n",
    "calculate_percentage(df, 'fridge')\n",
    "calculate_percentage(df, 'internet')\n",
    "\n",
    "\n",
    "print(df[['furniture_in_the_room', 'air_conditioner', 'dishwashing', 'fridge', 'internet']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of each value in 'only_street_view':\n",
      "only_street_view\n",
      "0.0    74.815988\n",
      "1.0    25.184012\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df['only_street_view'] = df['ÐžÐºÐ½Ð°'].apply(\n",
    "    lambda x: 1 if isinstance(x, str) and 'ÐÐ° ÑƒÐ»Ð¸Ñ†Ñƒ' in x else (0 if isinstance(x, str) else np.nan)\n",
    ")\n",
    "mode_only_street_view = df['only_street_view'].mode()[0]\n",
    "df['only_street_view'].fillna(mode_only_street_view, inplace=True)\n",
    "percent_counts = df['only_street_view'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Percentage of each value in 'only_street_view':\")\n",
    "print(percent_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1227,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting rid of columns \n",
    "df = df.drop(['ÐžÐºÐ½Ð°'], axis=1)\n",
    "df = df.drop(['ÐœÐ¾Ð¶Ð½Ð¾ Ñ Ð´ÐµÑ‚ÑŒÐ¼Ð¸/Ð¶Ð¸Ð²Ð¾Ñ‚Ð½Ñ‹Ð¼Ð¸'], axis=1)\n",
    "df = df.drop(['Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾'], axis=1)\n",
    "df = df.drop(['ÐÐ°Ð·Ð²Ð°Ð½Ð¸Ðµ Ð–Ðš'], axis=1)\n",
    "df = df.drop(['Ð¡ÐµÑ€Ð¸Ñ Ð´Ð¾Ð¼Ð°'], axis=1)\n",
    "df = df.drop(['Ð¡ÑÑ‹Ð»ÐºÐ° Ð½Ð° Ð¾Ð±ÑŠÑÐ²Ð»ÐµÐ½Ð¸Ðµ'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1228,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '../data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1228], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:3772\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3761\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3763\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3764\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3765\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3769\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3770\u001b[0m )\n\u001b[0;32m-> 3772\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[1;32m   3773\u001b[0m     path_or_buf,\n\u001b[1;32m   3774\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   3775\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[1;32m   3776\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m   3777\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m   3778\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[1;32m   3779\u001b[0m     quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[1;32m   3780\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m   3781\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[1;32m   3782\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m   3783\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[1;32m   3784\u001b[0m     quotechar\u001b[38;5;241m=\u001b[39mquotechar,\n\u001b[1;32m   3785\u001b[0m     date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[1;32m   3786\u001b[0m     doublequote\u001b[38;5;241m=\u001b[39mdoublequote,\n\u001b[1;32m   3787\u001b[0m     escapechar\u001b[38;5;241m=\u001b[39mescapechar,\n\u001b[1;32m   3788\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m   3789\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/formats/format.py:1186\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1165\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m   1168\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m   1169\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1184\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1185\u001b[0m )\n\u001b[0;32m-> 1186\u001b[0m csv_formatter\u001b[38;5;241m.\u001b[39msave()\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1189\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/formats/csvs.py:240\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    243\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    244\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,\n\u001b[1;32m    245\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression,\n\u001b[1;32m    246\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options,\n\u001b[1;32m    247\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    250\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    251\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    256\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    257\u001b[0m     )\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:737\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 737\u001b[0m     check_parent_directory(\u001b[38;5;28mstr\u001b[39m(handle))\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    741\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:600\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    598\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 600\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '../data'"
     ]
    }
   ],
   "source": [
    "df.to_csv('../data/data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
